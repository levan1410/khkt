# ============ IMPORTS ============
import streamlit as st
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image
import json
import pandas as pd
from datetime import datetime, date
import os, io, re, requests
import unicodedata
import difflib
from streamlit_mic_recorder import mic_recorder
import google.generativeai as genai
import urllib.parse as _u

# ============ PAGE CONFIG ============
st.set_page_config(page_title="AI S∆° c·ª©u & D·ªã ·ª©ng", layout="wide")
import streamlit as st

st.sidebar.header("üë§ Th√¥ng tin ng∆∞·ªùi d√πng")

with st.sidebar.form("user_info_form"):
    name = st.text_input("H·ªç v√† t√™n")
    age = st.number_input("Tu·ªïi", min_value=0, max_value=120, value=25)
    gender = st.selectbox("Gi·ªõi t√≠nh", ["Nam", "N·ªØ", "Kh√°c"])
    city = st.text_input("T·ªânh/Th√†nh ph·ªë hi·ªán t·∫°i", placeholder="VD: TP. H·ªì Ch√≠ Minh")
    district = st.text_input("Qu·∫≠n/Huy·ªán", placeholder="VD: Qu·∫≠n 1")
    ward = st.text_input("Ph∆∞·ªùng/X√£", placeholder="VD: Ph∆∞·ªùng B·∫øn Ngh√©")
    health_condition = st.text_area("T√¨nh tr·∫°ng s·ª©c kh·ªèe (n·∫øu c√≥)", 
                                    placeholder="VD: Ti·ªÉu ƒë∆∞·ªùng, tim m·∫°ch, d·ªã ·ª©ng thu·ªëc...")

    submitted = st.form_submit_button("‚úÖ L∆∞u th√¥ng tin")

if submitted:
    st.session_state.user_info = {
        "H·ªç t√™n": name,
        "Tu·ªïi": age,
        "Gi·ªõi t√≠nh": gender,
        "T·ªânh/Th√†nh ph·ªë": city,
        "Qu·∫≠n/Huy·ªán": district,
        "Ph∆∞·ªùng/X√£": ward,
        "T√¨nh tr·∫°ng s·ª©c kh·ªèe": health_condition
    }
    st.success("ƒê√£ l∆∞u th√¥ng tin! üéâ")

# ============ H√ÄM NH√öNG YOUTUBE ============
def render_youtube(url, height=460):
    """Nh√∫ng video YouTube b·∫±ng iframe, ki·ªÉm so√°t k√≠ch th∆∞·ªõc."""
    if "youtube.com" in url or "youtu.be" in url:
        if "youtu.be" in url:
            vid_id = url.split("/")[-1]
        else:
            vid_id = url.split("v=")[-1].split("&")[0]
        st.markdown(f'''
        <iframe width="100%" height="{height}"
                src="https://www.youtube.com/embed/{vid_id}?rel=0"
                frameborder="0" allowfullscreen></iframe>
        ''', unsafe_allow_html=True)
    else:
        st.video(url)

# ============ LOAD FILE TH√îNG TIN ============
with open("wound_info.json", "r", encoding="utf-8") as f:
    wound_info = json.load(f)

# ============ LOAD MODEL (cache) ============
MODEL_PATH = "model_class.keras"

@st.cache_resource
def load_cls_model(path=MODEL_PATH):
    return load_model(path)

model = load_cls_model(MODEL_PATH)

# ============ DANH S√ÅCH CLASS ============
class_names = [
    'Abrasions', 'Bruises', 'Burns', 'Cut',
    'Diabetic Wounds', 'Laceration', 'Normal',
    'Pressure Wounds', 'Surgical Wounds', 'Venous Wounds'
]

# ============ H√ÄM D·ª∞ ƒêO√ÅN ============
def predict_image(image: Image.Image):
    img_rgb = np.array(image.convert("RGB"))
    img_resized = cv2.resize(img_rgb, (160, 160))
    input_img = np.expand_dims(img_resized, axis=0)

    preds = model.predict(input_img)
    scores = tf.nn.softmax(preds[0]).numpy()  # n·∫øu model ƒë√£ softmax s·∫µn th√¨ v·∫´n ok
    pred_label = int(np.argmax(scores))
    confidence = float(scores[pred_label])
    return class_names[pred_label], confidence, scores

# ================== FIRST AID VIDEOS ==================
first_aid_videos = {
    "Abrasions": [
        "https://www.youtube.com/watch?v=K9Loqqoe3pE",
        "https://www.youtube.com/watch?v=IKcddYDbm6s",
        "https://www.youtube.com/watch?v=zIo41ndcKng"
    ],
    "Cut": [
        "https://www.youtube.com/watch?v=T-8Ac6RYZgI",
        "https://www.youtube.com/watch?v=1c6csZihf8M"
    ],
    "Burns": [
        "https://www.youtube.com/watch?v=EWH6LA5Cg2Y",
        "https://www.youtube.com/watch?v=J0ZtLnhpJxM"
    ],
    "Normal": [
        "https://www.youtube.com/watch?v=98yNdXf_Yw4"
    ],
    "Laceration": [
        "https://www.youtube.com/watch?v=R4DutP4ya9w",
        "https://www.youtube.com/watch?v=tRpHkcjgkdw"
    ],
    "Diabetic Wounds": [
        "https://www.youtube.com/watch?v=iPgnjJICzos",
        "https://www.youtube.com/watch?v=IHlV2M-8a2Q",
        "https://www.youtube.com/watch?v=N8M4qj6w82c"
    ],
    "Pressure Wounds": [
        "https://www.youtube.com/watch?v=BiqLzQ6nHWM",
        "https://www.youtube.com/watch?v=ynP1Ocooh3E"
    ],
    "Surgical Wounds": [
        "https://www.youtube.com/watch?v=R4DutP4ya9w",
        "https://www.youtube.com/watch?v=tRpHkcjgkdw"
    ],
    "Bruises": [
        "https://www.youtube.com/watch?v=4E_tScuwOYo",
        "https://www.youtube.com/watch?v=0uZpPpxM1aE"
    ],
    "Venous Wounds": [
        "https://www.youtube.com/watch?v=4ZUXy1kJqDg",
        "https://www.youtube.com/watch?v=nL-H3RSlFOQ"
    ],
}
def get_first_aid_videos(label: str):
    return first_aid_videos.get(label, [])

# ================== OTC / Rx MODULE (t·ªëi gi·∫£n) ==================
OTC_ACTIVES = {
    "paracetamol": {"alias": ["acetaminophen"], "note": "OTC li·ªÅu th∆∞·ªùng 325‚Äì500mg; c·∫£nh b√°o qu√° li·ªÅu"},
    "ibuprofen": {"note": "OTC li·ªÅu th·∫•p ng∆∞·ªùi l·ªõn; c√¢n nh·∫Øc d·∫° d√†y/ thai k·ª≥"},
    "loratadine": {"note": "kh√°ng histamine th·∫ø h·ªá 2 (√≠t bu·ªìn ng·ªß)"},
    "cetirizine": {"note": "kh√°ng histamine; c√≥ th·ªÉ g√¢y bu·ªìn ng·ªß nh·∫π"},
    "fexofenadine": {},
    "chlorpheniramine": {"note": "kh√°ng H1 ƒë·ªùi c≈©; g√¢y bu·ªìn ng·ªß r√µ"},
    "dextromethorphan": {"note": "·ª©c ch·∫ø ho; tr√°nh l·∫°m d·ª•ng"},
    "guaifenesin": {"note": "long ƒë·ªùm"},
    "ors": {"alias": ["oresol", "oral rehydration salts"], "note": "b√π n∆∞·ªõc ƒëi·ªán gi·∫£i"},
    "simethicone": {"note": "ƒë·∫ßy h∆°i, ch∆∞·ªõng b·ª•ng"},
    "aluminum hydroxide": {"alias": ["aluminium hydroxide"]},
    "magnesium hydroxide": {},
    "activated charcoal": {"alias": ["than hoat", "than ho·∫°t"]},
    "sodium cromoglicate": {"alias": ["sodium cromoglycate"], "note": "vi√™m k·∫øt m·∫°c/vi√™m m≈©i d·ªã ·ª©ng nh·∫π"},
    "oxymetazoline": {"note": "x·ªãt m≈©i: ch·ªâ d√πng ng·∫Øn ng√†y (‚â§3 ng√†y)"},
}
ALIASES = {}
for k, v in list(OTC_ACTIVES.items()):
    for a in v.get("alias", []):
        ALIASES[a.lower()] = k

def _norm(s: str):
    s = s.lower().strip()
    s = re.sub(r"[^a-z0-9 +./-]", " ", s)
    s = re.sub(r"\s+", " ", s)
    return s

def _tokenize_acts(s: str):
    s = _norm(s)
    parts = re.split(r"[+,/;]| with | and ", s)
    acts = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        if p in ALIASES:
            p = ALIASES[p]
        acts.append(p)
    return [a for a in acts if a]

def classify_rx_otc(input_text: str):
    acts = _tokenize_acts(input_text)
    if not acts:
        return {"status": "unknown", "hits": [], "reason": "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c ho·∫°t ch·∫•t."}
    hits, all_otc = [], True
    for a in acts:
        matched = None
        for k in OTC_ACTIVES.keys():
            if k in a:
                matched = k
                break
        if matched:
            hits.append((a, "OTC", OTC_ACTIVES[matched].get("note", "")))
        else:
            all_otc = False
            hits.append((a, "Rx", "Kh√¥ng n·∫±m trong danh s√°ch OTC r√∫t g·ªçn (local)"))
    status = "OTC" if all_otc else "Rx/Kh√¥ng ch·∫Øc"
    return {"status": status, "hits": hits, "reason": "D·ª±a tr√™n danh s√°ch OTC local (c·∫ßn x√°c minh khi kh√¥ng ch·∫Øc)."}

# ================== SESSION STATE ==================
if "wound_records" not in st.session_state:
    st.session_state.wound_records = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
# l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n g·∫ßn nh·∫•t (label, info, confidence)
if "last_prediction" not in st.session_state:
    st.session_state.last_prediction = None
if "user_info" not in st.session_state:
    st.session_state.user_info = {}

# ================== TABS ==================
tabs = st.tabs([
    "ü©∫ ·∫¢nh v·∫øt th∆∞∆°ng",
    "üíä Thu·ªëc OTC / K√™ ƒë∆°n",
    "ü§ñ B√°c sƒ© AI",
    "üìä Th·ªëng k√™",
    "üå¶Ô∏è Th·ªùi ti·∫øt & G·ª£i √Ω chƒÉm s√≥c",

])
tab1, tab2, tab3, tab4 ,tab5= tabs

# ================== TAB 1: ·∫¢NH V·∫æT TH∆Ø∆†NG ==================
with tab1:
    st.title("ü©∫ Ch∆∞∆°ng tr√¨nh ph√¢n lo·∫°i v·∫øt th∆∞∆°ng")
    st.write("Upload ·∫£nh ch·ª•p ƒë·ªÉ ch∆∞∆°ng tr√¨nh d·ª± ƒëo√°n lo·∫°i v·∫øt th∆∞∆°ng & g·ª£i √Ω ph∆∞∆°ng √°n s∆° c·ª©u.")
    st.divider()

    uploaded_file = st.file_uploader("Ch·ªçn m·ªôt ·∫£nh...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="·∫¢nh ƒë√£ upload", use_container_width=True)

        # D·ª± ƒëo√°n
        label, confidence, scores = predict_image(image)
        info = wound_info[label]
        # L∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o session ƒë·ªÉ c√°c tab kh√°c c√≥ th·ªÉ d√πng
        st.session_state.last_prediction = {
            "label": label,
            "info": info,
            "confidence": confidence,
            "scores": scores
        }

        left, right = st.columns([1, 1])

        with left:
            st.markdown(f"### ‚úÖ K·∫øt qu·∫£: **{info['ten_viet']} ({label})**")
            st.markdown(f"**ƒê·ªô tin c·∫≠y:** {confidence*100:.2f}%")

            # ====== TH√îNG TIN NGUY C∆† & KHI N√ÄO ƒêI KH√ÅM ======
            muc_do = info.get("muc_do", "Ch∆∞a x√°c ƒë·ªãnh")
            st.markdown(f"### ü©π **M·ª©c ƒë·ªô nguy c∆°:** {muc_do}")
            if any(k in muc_do.lower() for k in ["v·ª´a/n·∫∑ng", "n·∫∑ng"]):
                st.error("üö® Khuy·∫øn ngh·ªã: ƒê·∫øn c∆° s·ªü y t·∫ø ƒë·ªÉ ƒë∆∞·ª£c x·ª≠ tr√≠ chuy√™n s√¢u.")
            else:
                st.success("‚úÖ C√≥ th·ªÉ s∆° c·ª©u t·∫°i nh√† v√† theo d√µi th√™m 1‚Äì2 ng√†y.")

            with st.expander("‚ö†Ô∏è Khi n√†o c·∫ßn ƒëi kh√°m ngay?", expanded=False):
                st.write(info.get("canh_bao", "Theo d√µi tri·ªáu ch·ª©ng b·∫•t th∆∞·ªùng v√† ƒëi kh√°m khi c·∫ßn."))

            with st.expander("üìã M√¥ t·∫£ chi ti·∫øt", expanded=True):
                st.write(info["mo_ta"])

            with st.expander("üöë S∆° c·ª©u / ƒêi·ªÅu tr·ªã ban ƒë·∫ßu", expanded=True):
                st.write(info["so_cuu"])

        with right:
            st.subheader("üé¨ Video s∆° c·ª©u")
            vids = get_first_aid_videos(label)
            if not vids:
                st.info("Ch∆∞a c√≥ video cho lo·∫°i v·∫øt th∆∞∆°ng n√†y.")
            else:
                idx = 0 if len(vids) == 1 else st.selectbox(
                    "Ch·ªçn video:", range(len(vids)), format_func=lambda x: f"Video {x+1}"
                )
                render_youtube(vids[idx], height=460)

        st.divider()

        # --- üìù NH·∫¨T K√ù ---
        st.subheader("üìù Nh·∫≠t k√Ω b·ªánh √°n")
        with st.form("wound_log_form", clear_on_submit=True):
            c1, c2 = st.columns(2)
            with c1:
                pid = st.text_input("M√£ BN / H·ªç t√™n", placeholder="VD: BN_2025_001 ho·∫∑c Nguy·ªÖn VƒÉn A")
                age = st.text_input("Tu·ªïi", placeholder="VD: 32")
                phone = st.text_input("SƒêT (tu·ª≥ ch·ªçn)", placeholder="VD: 09xx...")
            with c2:
                severity = st.selectbox("M·ª©c ƒë·ªô", ["Nh·∫π", "V·ª´a", "N·∫∑ng"], index=1)
                final_label = st.text_input("Ch·∫©n ƒëo√°n (c√≥ th·ªÉ ch·ªânh)", value=f"{info['ten_viet']} ({label})")
                followup = st.date_input("Ng√†y t√°i kh√°m (tu·ª≥ ch·ªçn)", value=date.today())

            symptoms = st.text_area("Tri·ªáu ch·ª©ng/di·ªÖn ti·∫øn", placeholder="M√¥ t·∫£ chi ti·∫øt...")
            treatment = st.text_area("X·ª≠ tr√≠/ƒëi·ªÅu tr·ªã ƒë√£ th·ª±c hi·ªán", value=info["so_cuu"])
            notes = st.text_input("Ghi ch√∫ kh√°c", placeholder="D·ªã ·ª©ng thu·ªëc, b·ªánh n·ªÅn...")

            submitted = st.form_submit_button("üíæ L∆∞u nh·∫≠t k√Ω ca n√†y")
            if submitted:
                record = {
                    "Th·ªùi gian": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "M√£/BN": pid,
                    "Tu·ªïi": age,
                    "SƒêT": phone,
                    "M·ª©c ƒë·ªô": severity,
                    "Ch·∫©n ƒëo√°n (cu·ªëi)": final_label,
                    "Ch·∫©n ƒëo√°n (AI)": f"{info['ten_viet']} ({label})",
                    "ƒê·ªô tin c·∫≠y (%)": round(confidence*100, 2),
                    "Tri·ªáu ch·ª©ng": symptoms,
                    "X·ª≠ tr√≠ ban ƒë·∫ßu": treatment,
                    "Ghi ch√∫": notes,
                    "Ng√†y t√°i kh√°m": followup.strftime("%Y-%m-%d") if followup else "",
                    "T√™n file ·∫£nh": getattr(uploaded_file, "name", ""),
                }
                st.session_state.wound_records.append(record)
                st.success("ƒê√£ l∆∞u v√†o nh·∫≠t k√Ω! (·ªü b√™n d∆∞·ªõi)")

        if st.session_state.wound_records:
            st.markdown("#### üìö L·ªãch s·ª≠ nh·∫≠t k√Ω")
            df = pd.DataFrame(st.session_state.wound_records)
            st.dataframe(df, use_container_width=True, height=340)

            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            st.download_button("‚¨áÔ∏è T·∫£i to√†n b·ªô nh·∫≠t k√Ω (CSV)", data=csv_bytes,
                               file_name="wound_log.csv", mime="text/csv")
    else:
        st.info("H√£y ch·ªçn m·ªôt ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu ch·∫©n ƒëo√°n v√† ghi nh·∫≠t k√Ω.")

# ================== TAB 2: G·ª¢I √ù THU·ªêC + MUA ONLINE (Long Ch√¢u) + Ph√¢n lo·∫°i ==================
# ================== TAB 2: G·ª¢I √ù THU·ªêC + MUA ONLINE (Long Ch√¢u) + Ph√¢n lo·∫°i ==================
with tab2:
    st.header("üíä G·ª£i √Ω & Ph√¢n lo·∫°i thu·ªëc/thi·∫øt b·ªã")

    # Danh s√°ch g·ª£i √Ω thu·ªëc theo lo·∫°i v·∫øt th∆∞∆°ng
    # Danh s√°ch g·ª£i √Ω thu·ªëc theo lo·∫°i v·∫øt th∆∞∆°ng
    DRUG_SUGGESTIONS = {
        # 3 lo·∫°i ƒë√£ c√≥
        "v·∫øt tr·∫ßy x∆∞·ªõc": [ # Kh·ªõp v·ªõi Abrasions
            {"item": "Betadine 10%", "why": "S√°t khu·∫©n v·∫øt th∆∞∆°ng", "how": "R·ª≠a nh·∫π 2‚Äì3 l·∫ßn/ng√†y", "note": "Tr√°nh d√πng qu√° nhi·ªÅu"},
            {"item": "G·∫°c v√¥ tr√πng", "why": "B·∫£o v·ªá v√πng t·ªïn th∆∞∆°ng", "how": "Thay m·ªói 12h", "note": "Gi·ªØ kh√¥"}
        ],
        "b·ªèng nh·∫π": [ # Kh·ªõp v·ªõi Burns (n·∫øu l√† b·ªèng nh·∫π)
            {"item": "Silvirin cream 1%", "why": "Ch·ªëng nhi·ªÖm khu·∫©n, l√†m d·ªãu da", "how": "B√¥i m·ªèng 1‚Äì2 l·∫ßn/ng√†y", "note": "Ch·ªâ d√πng ngo√†i da"},
            {"item": "NaCl 0.9%", "why": "L√†m s·∫°ch v·∫øt b·ªèng", "how": "R·ª≠a nh·∫π tr∆∞·ªõc khi b√¥i thu·ªëc", "note": ""}
        ],
        "v·∫øt c·∫Øt nh·∫π": [ # Kh·ªõp v·ªõi Cut (n·∫øu l√† c·∫Øt nh·∫π)
            {"item": "Oxy gi√† 3%", "why": "R·ª≠a v·∫øt th∆∞∆°ng ban ƒë·∫ßu", "how": "Ch·ªâ d√πng 1 l·∫ßn ƒë·∫ßu ti√™n", "note": "Kh√¥ng l·∫°m d·ª•ng"},
            {"item": "M·ª° kh√°ng sinh (Fucidin, Tetracycline)", "why": "Ng·ª´a nhi·ªÖm tr√πng", "how": "B√¥i m·ªèng ng√†y 2 l·∫ßn", "note": ""}
        ],

        # 7 lo·∫°i c·∫ßn b·ªï sung (v√≠ d·ª•)
        # B·∫°n c·∫ßn t·ª± ƒë·ªãnh nghƒ©a n·ªôi dung g·ª£i √Ω cho c√°c lo·∫°i n√†y
        
        "v·∫øt b·∫ßm": [ # Kh·ªõp v·ªõi Bruises
            {"item": "Ch∆∞·ªùm l·∫°nh", "why": "Gi·∫£m s∆∞ng, co m·∫°ch", "how": "Ch∆∞·ªùm 10-15 ph√∫t, v√†i l·∫ßn/ng√†y (24h ƒë·∫ßu)", "note": "Kh√¥ng ch∆∞·ªùm ƒë√° tr·ª±c ti·∫øp l√™n da"},
            {"item": "Ch∆∞·ªùm n√≥ng", "why": "Tan m√°u b·∫ßm", "how": "Sau 24-48h", "note": ""}
        ],
        "lo√©t ti·ªÉu ƒë∆∞·ªùng": [ # Kh·ªõp v·ªõi Diabetic Wounds
            {"item": "G·∫°c chuy√™n d·ª•ng (hydrocolloid...)", "why": "Duy tr√¨ m√¥i tr∆∞·ªùng ·∫©m, b·∫£o v·ªá", "how": "Theo ch·ªâ ƒë·ªãnh BS", "note": "C·∫ßn ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt!"},
            {"item": "Dung d·ªãch s√°t khu·∫©n (Betadine/NaCl)", "why": "L√†m s·∫°ch", "how": "R·ª≠a nh·∫π nh√†ng", "note": "Tuy·ªát ƒë·ªëi tu√¢n th·ªß ch·ªâ ƒë·ªãnh y t·∫ø"}
        ],
        "v·∫øt r√°ch": [ # Kh·ªõp v·ªõi Laceration
            {"item": "G·∫°c √©p c·∫ßm m√°u", "why": "C·∫ßm m√°u ban ƒë·∫ßu", "how": "√âp ch·∫∑t v√† gi·ªØ", "note": "V·∫øt r√°ch s√¢u/r·ªông c·∫ßn ƒëi kh√¢u"},
            {"item": "BƒÉng d√°n (n·∫øu n√¥ng)", "why": "B·∫£o v·ªá", "how": "Sau khi s√°t khu·∫©n", "note": ""}
        ],
        "da l√†nh": [ # Kh·ªõp v·ªõi Normal
            {"item": "Kem d∆∞·ª°ng ·∫©m", "why": "Duy tr√¨ s·ª©c kh·ªèe da", "how": "H√†ng ng√†y", "note": "Kh√¥ng c·∫ßn can thi·ªáp y t·∫ø"}
        ],
        "lo√©t t√¨ ƒë√®": [ # Kh·ªõp v·ªõi Pressure Wounds
            {"item": "G·∫°c x·ªëp (foam dressing)", "why": "Gi·∫£m √°p l·ª±c, h√∫t d·ªãch", "how": "Theo ch·ªâ ƒë·ªãnh", "note": "Quan tr·ªçng nh·∫•t l√† thay ƒë·ªïi t∆∞ th·∫ø th∆∞·ªùng xuy√™n"},
            {"item": "ƒê·ªám ch·ªëng lo√©t", "why": "Ph√¢n t√°n √°p l·ª±c", "how": "S·ª≠ d·ª•ng cho b·ªánh nh√¢n", "note": ""}
        ],
        "v·∫øt m·ªï": [ # Kh·ªõp v·ªõi Surgical Wounds
            {"item": "G·∫°c v√¥ tr√πng", "why": "B·∫£o v·ªá v·∫øt kh√¢u", "how": "Thay bƒÉng theo ch·ªâ ƒë·ªãnh", "note": "Gi·ªØ kh√¥ tuy·ªát ƒë·ªëi (tr·ª´ khi ƒë∆∞·ª£c ph√©p)"},
            {"item": "Dung d·ªãch Povidine-Iodine", "why": "S√°t khu·∫©n khi thay bƒÉng", "how": "Theo h∆∞·ªõng d·∫´n c·ªßa BS", "note": ""}
        ],
        "lo√©t tƒ©nh m·∫°ch": [ # Kh·ªõp v·ªõi Venous Wounds
            {"item": "BƒÉng √©p (v·ªõ y khoa)", "why": "TƒÉng c∆∞·ªùng l∆∞u th√¥ng m√°u v·ªÅ tim", "how": "ƒêeo h√†ng ng√†y", "note": "C·∫ßn thƒÉm kh√°m chuy√™n khoa"},
            {"item": "G·∫°c t·∫©m b·∫°c (n·∫øu nhi·ªÖm tr√πng)", "why": "Di·ªát khu·∫©n", "how": "Theo ch·ªâ ƒë·ªãnh", "note": ""}
        ]
    }

    # H√†m chu·∫©n h√≥a chu·ªói
    def normalize_str(s: str):
        s = (s or "").lower()
        s = unicodedata.normalize("NFKD", s)
        s = "".join(ch for ch in s if not unicodedata.combining(ch))
        s = re.sub(r"[^a-z0-9\s]", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    # L·∫•y lo·∫°i v·∫øt th∆∞∆°ng t·ª´ d·ª± ƒëo√°n ho·∫∑c ch·ªçn th·ªß c√¥ng
    last = st.session_state.get("last_prediction")
    mapped_key = None
    pred_conf = None
    if last is not None:
        raw = last.get("info", {}).get("ten_viet", "")
        pred_conf = float(last.get("confidence", 0)) if last.get("confidence") is not None else None
        norm_pred = normalize_str(raw)
        norm_map = {normalize_str(k): k for k in DRUG_SUGGESTIONS.keys()}

        if norm_pred in norm_map:
            mapped_key = norm_map[norm_pred]
        else:
            for nk, orig in norm_map.items():
                if nk in norm_pred or norm_pred in nk:
                    mapped_key = orig
                    break
            if mapped_key is None:
                matches = difflib.get_close_matches(norm_pred, list(norm_map.keys()), n=1, cutoff=0.6)
                if matches:
                    mapped_key = norm_map[matches[0]]

    if mapped_key:
        src = f"AI ({pred_conf*100:.1f}% tin c·∫≠y)" if pred_conf is not None else "AI"
        st.caption(f"Lo·∫°i v·∫øt th∆∞∆°ng: {mapped_key} (Ngu·ªìn: {src})")
        wound_type = mapped_key
    else:
        wound_type = st.selectbox("Ch·ªçn lo·∫°i v·∫øt th∆∞∆°ng:", list(DRUG_SUGGESTIONS.keys()))

    # Hi·ªÉn th·ªã g·ª£i √Ω thu·ªëc
    found = False
    for key, suggestions in DRUG_SUGGESTIONS.items():
        if key == wound_type:
            found = True
            st.subheader("G·ª£i √Ω s·ª≠ d·ª•ng:")
            for s in suggestions:
                with st.container():
                    st.markdown(f"**{s['item']}**: {s['why']} | *{s['how']}*")
                    if s.get("note"):
                        st.caption(f"‚ö†Ô∏è L∆∞u √Ω: {s['note']}")
            break

    if not found:
        st.info("Hi·ªán ch∆∞a c√≥ g·ª£i √Ω c·ª• th·ªÉ cho lo·∫°i v·∫øt th∆∞∆°ng n√†y.")

    st.caption("Th√¥ng tin mang t√≠nh tham kh·∫£o. H√£y tham kh·∫£o √Ω ki·∫øn b√°c sƒ©/d∆∞·ª£c sƒ© tr∆∞·ªõc khi s·ª≠ d·ª•ng.")
    st.divider()

    # Tra c·ª©u c∆° s·ªü y t·∫ø
    with st.container():
        st.subheader("üè• C∆° s·ªü y t·∫ø g·∫ßn b·∫°n")
        city = (st.session_state.get("user_info", {}).get("T·ªânh/Th√†nh ph·ªë", "") or "").strip()
        if city:
            st.write(f"üîé Tra c·ª©u b·ªánh vi·ªán g·∫ßn: **{city}**")
            # S·ª≠a l·ªói URL Google Maps, tr√°nh c√°c domain kh√¥ng an to√†n
            # Chuy·ªÉn https://www.google.com/maps/search/b·ªánh+vi·ªán+g·∫ßn+...
            # th√†nh https://www.google.com/maps/search/?api=1&query=...
            query_encoded = _u.quote(f"b·ªánh vi·ªán t·∫°i {city}")
            gmap_url = f"https://www.google.com/maps/search/?api=1&query={query_encoded}"
            st.markdown(f"[üìç M·ªü Google Maps]({gmap_url})")
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng c·∫≠p nh·∫≠t T·ªânh/Th√†nh ph·ªë trong h·ªì s∆°.")
        st.markdown("[üåê Tra c·ª©u thu·ªëc (DAV)](https://dav.gov.vn/tra-cuu-thuoc.html)")
# ================== TAB 3: B√ÅC Sƒ® AI (CHAT) ==================
with tab3:
    st.header("ü§ñ T∆∞ v·∫•n AI - B√°c sƒ© ·∫£o")
    # Hi·ªÉn th·ªã l·ªãch s·ª≠
    for chat in st.session_state.chat_history:
        role = "üßë‚Äç‚öïÔ∏è B√°c sƒ© AI" if chat["role"] == "assistant" else "üßç‚Äç‚ôÇÔ∏è B·∫°n"
        with st.chat_message(chat["role"]):
            st.markdown(f"**{role}:** {chat['content']}")

    # Nh·∫≠p c√¢u h·ªèi
    user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n (vd: V·∫øt th∆∞∆°ng n√†y c√≥ c·∫ßn bƒÉng l·∫°i kh√¥ng?)")
    if user_input:
        st.chat_message("user").markdown(f"**B·∫°n:** {user_input}")
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        try:
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={"model": "gemma:2b", "prompt": user_input, "stream": False},
                timeout=60
            )
            response.raise_for_status()
            data = response.json()
            ai_text = data.get("response", "").strip()

            st.chat_message("assistant").markdown(f"**üßë‚Äç‚öïÔ∏è B√°c sƒ© AI:** {ai_text}")
            st.session_state.chat_history.append({"role": "assistant", "content": ai_text})

        except requests.exceptions.RequestException as e:
            st.error(f"üö´ L·ªói khi k·∫øt n·ªëi Ollama: {e}")
            st.info("‚öôÔ∏è Ki·ªÉm tra: ƒë√£ ch·∫°y `ollama serve` v√† `ollama pull gemma:2b` ch∆∞a?")

# ================== TAB 4: üìä TH·ªêNG K√ä & B√ÅO C√ÅO ==================
with tab4:
    st.header("üìä Th·ªëng k√™ & B√°o c√°o")

    if not st.session_state.wound_records:
        st.info("Ch∆∞a c√≥ ca n√†o trong nh·∫≠t k√Ω. H√£y ch·∫°y ph√¢n lo·∫°i ·ªü Tab 1 ƒë·ªÉ c√≥ d·ªØ li·ªáu th·ªëng k√™.")
    else:
        df = pd.DataFrame(st.session_state.wound_records).copy()

        # Chu·∫©n ho√° th·ªùi gian & ng√†y
        try:
            df["Th·ªùi gian"] = pd.to_datetime(df["Th·ªùi gian"])
        except Exception:
            pass
        if "Th·ªùi gian" in df.columns:
            df["Ng√†y"] = df["Th·ªùi gian"].dt.date
        else:
            df["Ng√†y"] = date.today()

        # --- B·ªô l·ªçc ---
        colf1, colf2, colf3 = st.columns([1,1,1])
        with colf1:
            min_day = min(df["Ng√†y"])
            max_day = max(df["Ng√†y"])
            d_from, d_to = st.date_input("Kho·∫£ng ng√†y", value=(min_day, max_day))
        with colf2:
            labels = sorted(df["Ch·∫©n ƒëo√°n (AI)"].unique().tolist()) if "Ch·∫©n ƒëo√°n (AI)" in df.columns else []
            pick_labels = st.multiselect("L·ªçc theo nh√£n", options=labels, default=labels)
        with colf3:
            severities = sorted(df["M·ª©c ƒë·ªô"].unique().tolist()) if "M·ª©c ƒë·ªô" in df.columns else []
            pick_sev = st.multiselect("L·ªçc theo m·ª©c ƒë·ªô", options=severities, default=severities)

        # √Åp b·ªô l·ªçc
        mask = (df["Ng√†y"] >= d_from) & (df["Ng√†y"] <= d_to)
        if pick_labels:
            mask &= df["Ch·∫©n ƒëo√°n (AI)"].isin(pick_labels)
        if pick_sev:
            mask &= df["M·ª©c ƒë·ªô"].isin(pick_sev)
        dff = df[mask].copy()

        st.markdown(f"**S·ªë ca sau l·ªçc:** {len(dff)}")

        # --- Bi·ªÉu ƒë·ªì ---
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("üóìÔ∏è S·ªë ca theo ng√†y")
            daily = dff.groupby("Ng√†y").size().rename("S·ªë ca")
            if len(daily) == 0:
                st.info("Kh√¥ng c√≥ d·ªØ li·ªáu trong kho·∫£ng l·ªçc.")
            else:
                st.line_chart(daily)

        with col2:
            st.subheader("üè∑Ô∏è Ph√¢n b·ªë theo nh√£n")
            if "Ch·∫©n ƒëo√°n (AI)" in dff.columns:
                by_label = dff["Ch·∫©n ƒëo√°n (AI)"].value_counts()
                if len(by_label) == 0:
                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
                else:
                    st.bar_chart(by_label)

        col3, col4 = st.columns(2)
        with col3:
            st.subheader("ü©π Ph√¢n b·ªë theo m·ª©c ƒë·ªô")
            if "M·ª©c ƒë·ªô" in dff.columns:
                by_sev = dff["M·ª©c ƒë·ªô"].value_counts()
                if len(by_sev) == 0:
                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu.")
                else:
                    st.bar_chart(by_sev)

        with col4:
            st.subheader("üéØ ƒê·ªô tin c·∫≠y (trung b√¨nh)")
            if "ƒê·ªô tin c·∫≠y (%)" in dff.columns and not dff["ƒê·ªô tin c·∫≠y (%)"].empty:
                avg_acc = round(float(dff["ƒê·ªô tin c·∫≠y (%)"].mean()), 2)
                st.metric("ƒê·ªô tin c·∫≠y trung b√¨nh (%)", avg_acc)
            else:
                st.info("Ch∆∞a c√≥ tr∆∞·ªùng 'ƒê·ªô tin c·∫≠y (%)'.")

        st.divider()
        st.subheader("üìù Ca g·∫ßn nh·∫•t (10 d√≤ng)")
        st.dataframe(
            dff.sort_values("Th·ªùi gian", ascending=False).head(10),
            use_container_width=True, height=260
        )

        # --- T·∫£i v·ªÅ CSV ---
        csv_all = dff.to_csv(index=False).encode("utf-8-sig")
        st.download_button("‚¨áÔ∏è T·∫£i d·ªØ li·ªáu ƒë√£ l·ªçc (CSV)", data=csv_all,
         file_name="thong_ke_wound_records.csv", mime="text/csv")
# ================== TAB 5: TH·ªúI TI·∫æT & G·ª¢I √ù CHƒÇM S√ìC ==================
with tab5:
    st.header("üå¶Ô∏è Th·ªùi ti·∫øt & G·ª£i √Ω chƒÉm s√≥c s·ª©c kh·ªèe")

    # L·∫•y s·∫µn t·ª´ sidebar n·∫øu c√≥
    city_tt = (st.session_state.user_info.get("T·ªânh/Th√†nh ph·ªë", "") or "").strip()
    city_tt = st.text_input(
        "Nh·∫≠p T·ªânh/Th√†nh ph·ªë ƒë·ªÉ xem th·ªùi ti·∫øt",
        value=city_tt,
        placeholder="VD: H√† N·ªôi, ƒê√† N·∫µng, TP. H·ªì Ch√≠ Minh"
    )

    if city_tt:
        with st.spinner(f"ƒêang c·∫≠p nh·∫≠t th·ªùi ti·∫øt t·∫°i {city_tt}..."):
            try:
                q_city = _u.quote(city_tt)
                url = f"https://wttr.in/{q_city}?format=j1"
                data = requests.get(url, timeout=10).json()

                cur = data["current_condition"][0]
                temp = float(cur["temp_C"])
                feels_like = float(cur["FeelsLikeC"])
                humidity = int(cur["humidity"])
                desc = cur["weatherDesc"][0]["value"]

                st.markdown(f"### üìç {city_tt}")
                colA, colB = st.columns(2)
                with colA:
                    st.metric("üå°Ô∏è Nhi·ªát ƒë·ªô (¬∞C)", f"{temp:.1f}", delta=f"C·∫£m gi√°c: {feels_like:.1f}¬∞C")
                with colB:
                    st.metric("üíß ƒê·ªô ·∫©m (%)", f"{humidity}%")
                st.write(f"**M√¥ t·∫£:** {desc}")

                # G·ª£i √Ω chƒÉm s√≥c r·∫•t c∆° b·∫£n
                if "m∆∞a" in desc.lower() or "rain" in desc.lower():
                    suggestion = "Mang √°o m∆∞a/√¥, gi√†y ch·ªëng tr∆∞·ª£t; lau kh√¥ ng∆∞·ªùi s·ªõm."
                elif temp <= 20:
                    suggestion = "M·∫∑c ·∫•m, u·ªëng n∆∞·ªõc ·∫•m; tr√°nh gi√≥ l·∫°nh bu·ªïi s√°ng."
                elif temp >= 33:
                    suggestion = "U·ªëng ƒë·ªß n∆∞·ªõc, tr√°nh n·∫Øng g·∫Øt; b√¥i ch·ªëng n·∫Øng khi ra ngo√†i."
                elif humidity >= 85:
                    suggestion = "ƒê·ªô ·∫©m cao: gi·ªØ kh√¥ tho√°ng, ph∆°i ƒë·ªì k·ªπ, ch√∫ √Ω da/n·∫•m."
                else:
                    suggestion = "Th·ªùi ti·∫øt d·ªÖ ch·ªãu; duy tr√¨ ƒÉn ng·ªß ƒëi·ªÅu ƒë·ªô."

                st.success(f"üí° G·ª£i √Ω chƒÉm s√≥c: {suggestion}")

                # ƒê·ªì d√πng n√™n chu·∫©n b·ªã (ng·∫Øn g·ªçn)
                items = []
                if "m∆∞a" in desc.lower() or "rain" in desc.lower():
                    items += ["√Åo m∆∞a/√¥", "KhƒÉn lau kh√¥"]
                if temp <= 20:
                    items += ["√Åo kho√°c ·∫•m", "Kh·∫©u trang"]
                if temp >= 33:
                    items += ["M≈©/n√≥n", "Kem ch·ªëng n·∫Øng", "B√¨nh n∆∞·ªõc"]
                if not items:
                    items = ["Kh·∫©u trang", "N∆∞·ªõc u·ªëng"]

                st.markdown("**üß≥ G·ª£i √Ω mang theo:** " + ", ".join(items))
                st.caption("Ngu·ªìn: wttr.in (th·ªùi gian th·ª±c)")

            except Exception as e:
                st.error(f"Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu th·ªùi ti·∫øt: {e}")
    else:
        st.info("Nh·∫≠p T·ªânh/Th√†nh ph·ªë ƒë·ªÉ xem th·ªùi ti·∫øt v√† g·ª£i √Ω chƒÉm s√≥c.")
